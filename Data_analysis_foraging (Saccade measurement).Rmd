---
title: "Data analysis"
author: "Jana, Sophia, Asger, Rebecca, Dora (JSARD)"
date: "2/11/2020"
output: html_document
---

## Code for data analysis

```{r setup, include=FALSE}
pacman::p_load(knitr, kableExtra, tidyverse, ggpubr, ggrepel, grid, jpeg, lme4, DHARMa, MuMIn)
opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
theme_set(theme_bw())
```

Load the samples data, flip the Y-axis, and filter data rows with weird timestamps (>= 41202 ms)

```{r load data}
Samples <- read_csv("Exported_EyeLink_data/Cleaned/Samples_merged.csv") %>% 
  mutate(GazeY = 1051-GazeY, Fix_MeanY = 1051-Fix_MeanY) %>% 
  filter(Time<=41202)
```

This is the example analysis thqt we ran in class last Wednesday, looking at saccade amplitude. Use this as template for other analyses (but make sure to think about the underlying distribution of whatever you are modeling)

First, make a summary dataset for saccade amplitude:

```{r}
Saccades <- Samples[!is.na(Samples$SaccadeNo) & Samples$Task == "Foraging",] %>% 
  group_by(ParticipantID, Trial, SaccadeNo) %>% 
  summarize(SaccadeAmplitude = mean(Sac_Amplitude), ForagingType = ForagingType[1], Stimulus = Stimulus[1]) %>% 
  filter(!is.na(SaccadeAmplitude))

head(Saccades)

ggplot(Saccades, aes(SaccadeAmplitude, color = ForagingType)) + geom_density()
```

Make two models: a "null" gaussian model (which does not make sense given the distribution of saccade amplitude), and a lognormal model (to accommodate the distribution of the data):

```{r}
mGaus <-
  glmer(
    SaccadeAmplitude ~ ForagingType + (1 + ForagingType |
                                         ParticipantID) + (1 + ForagingType | Stimulus),
    family = gaussian(link = "identity"),
    data = Saccades
  )

mLog <-
  glmer(
    SaccadeAmplitude ~ ForagingType + (1 + ForagingType |
                                         ParticipantID) + (1 + ForagingType | Stimulus),
    family = gaussian(link = "log"),
    data = Saccades
  )
```

Look at the model summaries:

# DeadlySinOfFrequencyStats # FreqStats # FreakStats
(Reason why Bayeisian stats are cooler).
# P-valuesAreSilleh

# Let's not go to Frequency Stats, 'tis a silly place.

```{r}

summary(mLog)

summary(Saccades$SaccadeAmplitude)
```

Generate predictions from the models and plot their density, then compare the predictions to the distribution of the actual data. What do you notice?

```{r}
pm1 <- predict(mGaus)
pm2 <- predict(mLog)

plot(density(pm1))
plot(density(pm2))
plot(density(Saccades$SaccadeAmplitude))
```

Numericaly compare the model predictions to the actual data (in absolute values) in order to get an idea of how well the model predicts the data:

```{r}
summary(abs(pm1-Saccades$SaccadeAmplitude))
summary(abs(pm2-Saccades$SaccadeAmplitude))


summary(abs(pm1-Saccades$SaccadeAmplitude)) - summary(abs(pm2-Saccades$SaccadeAmplitude))

```

We can compare observed data and model predictions more formally by looking at the residuals of the fitted models. To do this, we use the DHARMa (Residual Diagnostics for HierArchical Regression Models) package:

```{r}
# first we use the simulateResiduals() function to compute the (scaled) residuals of the fitted model
# n = 250 is the number of simulations that we want DHARMa to run
dGaus <- simulateResiduals(mGaus, n = 250)
dLog <- simulateResiduals(mLog, n = 250)
```

Now we can plot the residuals for the gaussian and lognormal models and see which model does best. Do we notice any  differences?

```{r}
plot(dGaus)
plot(dLog)
```

Lastly, we can use the r.squaredGLMM() function from the MuMIn (Multi-Model Inference) package in order to calculate conditional and marginal R^2 of the two models to get a measure of their goodness of fit:

```{r}
r.squaredGLMM(mGaus)
r.squaredGLMM(mLog)
```
